{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TvsJSeOzMNM"
   },
   "source": [
    "# Metodología"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUnLbI8fLkUK"
   },
   "source": [
    "## Recolección de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAPlKonvL1ST"
   },
   "source": [
    "Importamos librerías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0BVO7X2LmiK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import random as rd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJFDR0vsL4U3"
   },
   "source": [
    "Obtenemos la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rmK49Z5MB2w",
    "outputId": "5cce4194-17c4-4a9e-b9a8-c95d9789430c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bn2Vi6KNAVd"
   },
   "outputs": [],
   "source": [
    "DB = pd.read_csv('/content/drive/MyDrive/ML_TSIV/KNN/TumorDataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E08MfSrovmq_"
   },
   "source": [
    "En este caso especial, eliminamos desde el ahora dos atributos de la base de datos innecesarios, al ser solo de seguimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2w4EHm7vBQ2"
   },
   "outputs": [],
   "source": [
    "DB = DB[DB.columns[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "OP2_fUdoNFFf",
    "outputId": "654ad9fa-2679-4d59-b515-19f4807f146d"
   },
   "outputs": [],
   "source": [
    "DB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LA7W5QYL96e"
   },
   "source": [
    "Desplegamos una muestra de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "xaGjety8OP4d",
    "outputId": "3e86a205-93ed-4952-b9ec-c6318d156cee"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(DB, vars = DB.columns[1:6], hue = DB.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KM4ylLHDPd-B"
   },
   "source": [
    "## Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "n2QZIBH5w8XN",
    "outputId": "9be0a9b8-6b06-4246-cfd6-a22bfa02f986"
   },
   "outputs": [],
   "source": [
    "Titles = list(DB.columns)\n",
    "\n",
    "Titles_str = []\n",
    "for title in Titles:\n",
    "  if type(DB[title][0]) == str:\n",
    "    Titles_str.append(title)\n",
    "\n",
    "for title in Titles_str:\n",
    "  types = pd.unique(DB[title])\n",
    "  i = 0\n",
    "  for data in types:\n",
    "    data_loc = np.where(DB[title] == data)[0]\n",
    "    for pos in data_loc:\n",
    "      DB[title][pos] = i\n",
    "    i += 1\n",
    "\n",
    "DB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onSwrv4lo45b"
   },
   "source": [
    "### Analizamos los datos de forma elemental."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKsTrE-akX9V"
   },
   "source": [
    "Calculamos la cantidad de AtributOs e Instancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRDuzQ7tdbCp"
   },
   "outputs": [],
   "source": [
    "NoAtributos = len(DB.T)\n",
    "NoInstancias = len(DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwthNkUjTqwW"
   },
   "source": [
    "Convertimos la base de datos en un arreglo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5SOgERUTW9p"
   },
   "outputs": [],
   "source": [
    "DBar = DB.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQclTs0lTkwc"
   },
   "source": [
    "Calculamos el máximo y mínimo de cada Atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwJsFVkrTkRj"
   },
   "outputs": [],
   "source": [
    "MaximoDeAtributos = []\n",
    "MinimoDeAtributos = []\n",
    "for idx in range(NoAtributos):\n",
    "  CaractMax = max(DBar.T[idx])\n",
    "  CaractMin = min(DBar.T[idx])\n",
    "  MaximoDeAtributos.append(CaractMax)\n",
    "  MinimoDeAtributos.append(CaractMin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGFP8cPBpFpQ"
   },
   "source": [
    "Calculamos el primer y tercer cuartil (Q1 y Q3, respectivamente), de cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bo9by3bkpLXT"
   },
   "outputs": [],
   "source": [
    "Q1 = []\n",
    "Q3 = []\n",
    "for idx in range(NoAtributos):\n",
    "  if str(type(DBar[0][idx]))[8 : -2] != 'str':\n",
    "    atrib = DBar.T[idx].tolist()\n",
    "    atrib.sort()\n",
    "\n",
    "    NoCuartil1 = 0.25 * (NoInstancias + 1)\n",
    "    if str(type(NoCuartil1))[8 : -2] != 'int':\n",
    "      pos1 = round(NoCuartil1)\n",
    "      if pos1 < NoCuartil1:\n",
    "        pos2 = pos1 + 1\n",
    "      else:\n",
    "        pos2 = pos1 - 1\n",
    "      NoCuartil1 = round((pos1 + pos2) / 2)\n",
    "    Cuartil1 = atrib[NoCuartil1 + 1]\n",
    "    incremento = 1\n",
    "    while True:\n",
    "      if str(Cuartil1) == 'nan':\n",
    "          Cuartil1 = atrib[NoCuartil1]\n",
    "          NoCuartil1 -= 1\n",
    "      else:\n",
    "        break\n",
    "\n",
    "    NoCuartil3 = 0.7 * (NoInstancias + 1)\n",
    "    if str(type(NoCuartil3))[8 : -2] != 'int':\n",
    "      pos1 = round(NoCuartil3)\n",
    "      if pos1 < NoCuartil3:\n",
    "        pos2 = pos1 + 1\n",
    "      else:\n",
    "        pos2 = pos1 - 1\n",
    "      NoCuartil3 = round((pos1 + pos2) / 2)\n",
    "    Cuartil3 = atrib[NoCuartil3 + 1]\n",
    "    while True:\n",
    "      if str(Cuartil3) == 'nan':\n",
    "          Cuartil3 = atrib[NoCuartil3]\n",
    "          NoCuartil3 -= 1\n",
    "      else:\n",
    "        break\n",
    "\n",
    "  Q1.append(Cuartil1)\n",
    "  Q3.append(Cuartil3)\n",
    "Q1 = np.array(Q1)\n",
    "Q3 = np.array(Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBdx-w4Coovw"
   },
   "source": [
    "### Normalizamos los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwBgq2TtPiFF"
   },
   "source": [
    "Elegimos un rango de normalización entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09vLi9W1Twhn"
   },
   "outputs": [],
   "source": [
    "MaximoNormalizado = 1\n",
    "MinimoNormalizado = 0\n",
    "RangoNormalizado = MaximoNormalizado - MinimoNormalizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9ZoFhCjT7xG"
   },
   "source": [
    "Normalizamos los valores y obtenemos el nuevo arreglo de valores normalizados 'DBNar'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2KxJ6SmPqli"
   },
   "outputs": [],
   "source": [
    "DBNorm = []\n",
    "for idx in range(NoAtributos):\n",
    "  \n",
    "  CaractNorm = []\n",
    "  if str(type(DBar[0][idx]))[8 : -2] != 'str':\n",
    "    \n",
    "    RangodeDatos = MaximoDeAtributos[idx] - MinimoDeAtributos[idx]\n",
    "    for idx2 in range(NoInstancias):\n",
    "\n",
    "      if str(DBar[idx2][idx]) != 'nan':\n",
    "        D = DBar[idx2][idx] - MinimoDeAtributos[idx]\n",
    "        DPct = D / RangodeDatos\n",
    "        dNorm = RangoNormalizado * DPct\n",
    "        Normalizado = MinimoNormalizado + dNorm\n",
    "        CaractNorm.append(Normalizado)\n",
    "      else:\n",
    "        CaractNorm.append(DBar[idx2][idx])\n",
    "  \n",
    "  else:\n",
    "    for idx2 in range(NoInstancias):\n",
    "      CaractNorm.append(DBar[idx2][idx])\n",
    "  \n",
    "  DBNorm.append(CaractNorm)\n",
    "\n",
    "DBNar = np.array(DBNorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLPfiMAsRjz3"
   },
   "source": [
    "Visualizamos una parte de la base de datos con los valores normalizados, para garantizar una correcta transformación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Brejl8imU4r7",
    "outputId": "4ae2e32a-d49e-465f-b65a-84f4d934f84a"
   },
   "outputs": [],
   "source": [
    "DBNarT = DBNar.T\n",
    "showDB = pd.DataFrame(DBNarT)\n",
    "showDB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTpPPDKh791N"
   },
   "source": [
    "## Análisis de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipND8eHZ-VnE"
   },
   "source": [
    "### Generación de X e Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tppF3k4yU5jf"
   },
   "source": [
    "Reordenamos aleatoriamente la lista de la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2dZeRQxU-Db"
   },
   "outputs": [],
   "source": [
    "RDBNar = rd.sample(DBNar.T.tolist(), k=len(DBNar.T))\n",
    "RDBNar = np.array(RDBNar).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f9kXWao9PVx"
   },
   "source": [
    "Seleccionamos el atributo para nuestro valor objetivo 'Y' y el resto 'X' como ejemplos para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4RihNYc5bf2"
   },
   "outputs": [],
   "source": [
    "X = DBNar[1:]\n",
    "X = X.T\n",
    "Y = DBNar[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqLXYl3xBEVz"
   },
   "source": [
    "### Serie de funciones creadas para obtener las métricas de rendimiento de un modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q38oFu1-BB6E"
   },
   "outputs": [],
   "source": [
    "#Función para obtener el error cuadrático medio, recibe las listas de los valores predichos y los valores reales.\n",
    "def MSE(MSEpred, MSEreal):\n",
    "  MSEsize = len(MSEreal)\n",
    "  MSEt = 0\n",
    "  for MSEidx in range(MSEsize):\n",
    "    MSEt += (MSEpred[MSEidx] - MSEreal[MSEidx])**2\n",
    "  MSEf = MSEt / MSEsize\n",
    "  return(MSEf)\n",
    "\n",
    "#Función para calcular la tasa de clasificación, recibe las listas de los valores predichos y los valores reales.\n",
    "def TC(TCpred, TCreal):\n",
    "  TCsize = len(TCpred)\n",
    "  TCt = 0\n",
    "  for TCidx in range(TCsize):\n",
    "    if TCpred[TCidx] != TCreal[TCidx]:\n",
    "      TCt += 1\n",
    "  TCf = 1 - TCt / TCsize\n",
    "  return(TCf)\n",
    "\n",
    "#Función que obtiene los valores de la matriz de confusión (TP, FN, FP, TN), recibe las listas de los valores predichos y los valores reales.\n",
    "#Solo funciona a partir de esta métrica para etiquetas con longitud = 2, es decir binarias.\n",
    "#Se decidió utilizar estas métricas en específico para nuestra base de datos ya que los tipos de sus etiquetas solo son 2, 1 o 0.\n",
    "#Para proyectos con más categorías en sus etiquetas, se debe usar directamente la Exactitud, que es con la que se forma la Matriz de confusión.\n",
    "def MatConf(MCpred, MCreal):\n",
    "  MCsize = len(MCpred)\n",
    "  MCTP = 0\n",
    "  MCFN = 0\n",
    "  MCFP = 0\n",
    "  MCTN = 0\n",
    "  for MCidx in range(MCsize):\n",
    "    if MCreal[MCidx] == 1:\n",
    "      if MCpred[MCidx] == 1:\n",
    "        MCTP += 1\n",
    "      else:\n",
    "        MCFN += 1\n",
    "    else:\n",
    "      if MCpred[MCidx] == 1:\n",
    "        MCFP += 1\n",
    "      else:\n",
    "        MCTN += 1\n",
    "  return(MCTP, MCFN, MCFP, MCTN)\n",
    "\n",
    "#Funciones para calcular la tasa de clasificación (TdC), incluyendo la exactitud (TdCExact), precisión (TdCPre), sensitividad o Recall (TdCSens)\n",
    "#y puntaje F - beta con beta = 1, es decir, F1 (TdCF1).\n",
    "def TdC(TdCTP, TdCFN, TdCFP, TdCTN):\n",
    "  TdCExact = (TdCTP + TdCTN) / (TdCTP + TdCTN + TdCFP + TdCFN)\n",
    "  TdCPre = TdCTP / (TdCTP + TdCFP)\n",
    "  TdCSens = TdCTP / (TdCTP + TdCFN)\n",
    "  TdCF1 = (2 * TdCTP) / (2 * TdCTP + TdCFP + TdCFN)\n",
    "  return([TdCExact, TdCPre, TdCSens, TdCF1])\n",
    "\n",
    "#Función para obtener las estadísticas de rendimiento, recibe las listas de los valores predichos y los valores reales.\n",
    "def Estadisticas(EYPred, EYreal):\n",
    "  EMSE = MSE(EYPred, EYreal)\n",
    "  ETC = TC(EYPred, EYreal)\n",
    "  ETP, EFN, EFP, ETN = MatConf(EYPred, EYreal)\n",
    "  EExact, EPrecis, ESens, EF1 = TdC(ETP, EFN, EFP, ETN)\n",
    "  Estadistica = [EMSE, ETC, EExact, EPrecis, ESens, EF1]\n",
    "  return(Estadistica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlfcnVhf-Z6g"
   },
   "source": [
    "### Creación de una clase propia, la cual fungirá como un clasificador KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PjkXTn9WEDv"
   },
   "outputs": [],
   "source": [
    "class KNN():\n",
    "  def __init__(self):\n",
    "    self.bestK = 3\n",
    "\n",
    "  #Función para entrenar un modelo de KNN, cuyo entrenamiento consiste en encontrar la mejor K de acuerdo a las estadísticas de rendimiento.\n",
    "  #La cantidad de épocas (fEpocas) consiste en el número de Ks distintas a probar, siendo siempre impares.\n",
    "  #La prioridad asigna a qué medida de rendimiento tomar en cuenta para determinar el mejor K.\n",
    "  def fit(self, fXTrainP, fYTrainP, fXTestP, fYTestP, fEpocasP = 4, fpriorityP = 'Precision'):\n",
    "    self.fXtrain = fXTrainP\n",
    "    self.fYtrain = fYTrainP\n",
    "    self.fXtest = fXTestP\n",
    "    self.fYtest = fYTestP\n",
    "    self.fpriority = fpriorityP\n",
    "    self.fEpocas = fEpocasP\n",
    "    self.fKfin = 3 + 2 * (self.fEpocas - 1)\n",
    "    self.bestK = self.SelectK()\n",
    "  \n",
    "  #Función para predecir un nuevo punto a partir del modelo entrenado.\n",
    "  def PrednewPoint(self, KNNXnewPoint):\n",
    "    self.newYpred = self.XpredP(KNNXnewPoint)\n",
    "    return(self.newYpred)\n",
    "\n",
    "  #Función que se encarga de calcular la distancia Euclidiana entre dos puntos de n dimensionalidad.\n",
    "  def Euc_Dist(self, EuX1, EuX2):\n",
    "    EuInSqua = 0\n",
    "    for EuIdx in range(len(EuX1)):\n",
    "      EuInSqua += (EuX2[EuIdx] - EuX1[EuIdx])**2\n",
    "    EucDistance = EuInSqua**0.5\n",
    "    return(EucDistance)\n",
    "  \n",
    "  #Función que obtiene las distancias entre un nuevo punto y todos los puntos de entrenamiento.\n",
    "  def XDistances(self, XNew):\n",
    "    XDists = []\n",
    "    for Xpoint in self.fXtrain:\n",
    "      XDists.append(self.Euc_Dist(XNew, Xpoint))\n",
    "    return(XDists)\n",
    "\n",
    "  #Función dedicada a calcular los K puntos más cercanos respecto a un nuevo punto.\n",
    "  def KClosest(self, Knew):\n",
    "    KDists = self.XDistances(Knew)\n",
    "    KsortDists = sorted(KDists)\n",
    "    KClosestDist =  KsortDists[:self.fKactual]\n",
    "    KCposs = []\n",
    "    for KCDist in KClosestDist:\n",
    "      KCp = np.where(KDists == KCDist)\n",
    "      KCposs.append(KCp[0][0])\n",
    "    self.KClosestPoints = []\n",
    "    for KCpos in KCposs:\n",
    "      self.KClosestPoints.append(self.fXtrain[KCpos])\n",
    "    return(self.KClosestPoints)\n",
    "\n",
    "  #Función que busca determinar entre los K puntos más cercanos a un nuevo punto, el número de puntos de cada categoría.\n",
    "  def NumPointsxCat(self, Nnew):\n",
    "    NClosestPoints = self.KClosest(Nnew)\n",
    "    Npos = []\n",
    "    for Npoint in NClosestPoints:\n",
    "      NW = np.where(self.fXtrain == Npoint)\n",
    "      Npos.append(NW[0][0])\n",
    "    CatxPoint = []\n",
    "    for Nelement in Npos:\n",
    "      CatxPoint.append(self.fYtrain[Nelement])\n",
    "    return(CatxPoint)\n",
    "\n",
    "  #Función para determinar el valor predicho de un nuevo punto.\n",
    "  def XpredP(self, XnewP):\n",
    "    XCatP = self.NumPointsxCat(XnewP)\n",
    "    XCounterP = Counter(XCatP)\n",
    "    first = XCounterP.most_common(1)\n",
    "    XYpredP = first[0][0]\n",
    "    return(XYpredP)\n",
    "\n",
    "  #Función que se encarga de calcular los valores predichos de todos los punto de prueba.\n",
    "  def PredAllP(self):\n",
    "    PAYpred = []\n",
    "    for PApoint in self.fXtest:\n",
    "      PAYpred.append(self.XpredP(PApoint))\n",
    "    return(PAYpred)\n",
    "\n",
    "  #Función que obtiene las estadísticas de rendimiento con diferentes Ks.\n",
    "  def fstatistics(self):\n",
    "    self.fKactual = 3\n",
    "    fEstadisticas = []\n",
    "    print(str(self.fpriority), 'con', str(self.fEpocas), 'K distintas:')\n",
    "    while self.fKactual <= self.fKfin:\n",
    "      fYpred = self.PredAllP()\n",
    "      fEstadistica = Estadisticas(fYpred, self.fYtest)\n",
    "      print(str(self.fpriority), 'con k =', str(self.fKactual) + ':', str(fEstadistica[3]) + '.')\n",
    "      fEstadisticas.append(fEstadistica)\n",
    "      self.fKactual += 2\n",
    "    return(fEstadisticas)\n",
    "  \n",
    "  #Función que selecciona la mejor K, de acuerdo a su rendimiento.\n",
    "  def SelectK(self):\n",
    "    SEstadisticas = self.fstatistics()\n",
    "    SMSE = []\n",
    "    STC = []\n",
    "    SExact = [] \n",
    "    SPrecis = []\n",
    "    SSens = []\n",
    "    SF1 = []\n",
    "    for Selement in SEstadisticas:\n",
    "      SMSE.append(Selement[0])\n",
    "      STC.append(Selement[1])\n",
    "      SExact.append(Selement[2])\n",
    "      SPrecis.append(Selement[3])\n",
    "      SSens.append(Selement[4])\n",
    "      SF1.append(Selement[5])\n",
    "\n",
    "    self.MSE = min(SMSE)\n",
    "    self.TC = max(STC)\n",
    "    self.Exact = max(SExact)\n",
    "    self.Precis = max(SPrecis)\n",
    "    self.Rec = max(SSens)\n",
    "    self.F1 = max(SF1)\n",
    "\n",
    "    if self.fpriority == 'MSE':\n",
    "      SW = np.where(SMSE == self.MSE) \n",
    "    elif self.fpriority == 'TdC':\n",
    "      SW = np.where(STC == self.TC)\n",
    "    elif self.fpriority == 'Exactitud':\n",
    "      SW = np.where(SExact == self.Exact)\n",
    "    elif self.fpriority == 'Precision':\n",
    "      SW = np.where(SPrecis == self.Precis)\n",
    "    elif self.fpriority == 'Recall':\n",
    "      SW = np.where(SSens == self.Rec)\n",
    "    elif self.fpriority == 'F1':\n",
    "      SW = np.where(SF1 == self.F1)\n",
    "    else:\n",
    "      SW = np.where(SPrecis == self.Precis)\n",
    "\n",
    "    SBestPos = SW[0]\n",
    "    BestK = 3 + 2 * (SBestPos - 1)\n",
    "    return(BestK)\n",
    "  \n",
    "  #Función que permite obetener la precisión final del modelo, tomado con la mejor K.\n",
    "  def get_precision(self):\n",
    "    return(self.Precis)\n",
    "\n",
    "  #Función que permite obetener la estadística final seleccionada por 'GSName' del cualqueir modelo generado.\n",
    "  def get_stadistict(self, GSName):\n",
    "    if GSName == 'MSE':\n",
    "      GSResult = self.MSE\n",
    "    elif GSName == 'TdC':\n",
    "      GSResult = self.TC\n",
    "    elif GSName == 'Exactitud':\n",
    "      GSResult = self.Exact\n",
    "    elif GSName == 'Precision':\n",
    "      GSResult = self.Precis\n",
    "    elif GSName == 'Recall':\n",
    "      GSResult = self.Rec\n",
    "    elif GSName == 'F1':\n",
    "      GSResult = self.F1\n",
    "    else:\n",
    "      GSResult = self.Precis\n",
    "    return(GSResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiRC_o30AA-h"
   },
   "source": [
    "## Entrenamos un modelo con el algoritmo de KNN generado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b10zOnwH_en0"
   },
   "source": [
    "### Separamos a X e Y en conjuntos para el entrenamiento y para las pruebas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4S5_I9kGSOLT"
   },
   "source": [
    "Primeramente apartamos una sección pequeña de datos de validación para las pruebas finales (Xval, Yval) y dejamos el resto para el entrenamiento (Xres, Yres).\n",
    "\n",
    "Nota: \n",
    "\n",
    "Los datos de X y Y ya están re-ordenados aleatoriamente al haber sido formados por una variación de la base de datos re-ordenada aleatoriamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6IgVukytSM1d"
   },
   "outputs": [],
   "source": [
    "Xres, Xval, Yres, Yval = train_test_split(X, Y, test_size = 0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svZqmla0VN-9"
   },
   "source": [
    "### Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVaOVCPA_RjM"
   },
   "source": [
    "Separaremos los valores en cada iteración de acuerdo al método de validación cruzada (K-FOLD), tomando un K = 5, es decir un 5-FOLD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8hrpx_vwgpbp"
   },
   "outputs": [],
   "source": [
    "DBsize = len(Xres)\n",
    "DBp = DBsize / 5\n",
    "VDB = int(DBp)\n",
    "CDB = int(DBp * 2)\n",
    "SDB = int(DBp * 3)\n",
    "ODB = int(DBp * 4)\n",
    "\n",
    "Xtest1, Xtrain1, Ytest1, Ytrain1 = train_test_split(Xres, Yres, test_size = 0.80, shuffle = False)\n",
    "\n",
    "Xtrain2, Ytrain2 = Xres[:VDB].tolist() + Xres[CDB:].tolist(), Yres[:VDB].tolist() + Yres[CDB:].tolist()\n",
    "Xtrain2, Ytrain2 = np.array(Xtrain2), np.array(Ytrain2)\n",
    "Xtest2, Ytest2 = Xres[VDB:CDB], Yres[VDB:CDB]\n",
    "\n",
    "Xtrain3, Ytrain3 = Xres[:CDB].tolist() + Xres[SDB:].tolist(), Yres[:CDB].tolist() + Yres[SDB:].tolist()\n",
    "Xtrain3, Ytrain3 = np.array(Xtrain3), np.array(Ytrain3)\n",
    "Xtest3, Ytest3 = Xres[CDB:SDB], Yres[CDB:SDB]\n",
    "\n",
    "Xtrain4, Ytrain4 = Xres[:SDB].tolist() + Xres[ODB:].tolist(), Yres[:SDB].tolist() + Yres[ODB:].tolist()\n",
    "Xtrain4, Ytrain4 = np.array(Xtrain4), np.array(Ytrain4)\n",
    "Xtest4, Ytest4 = Xres[SDB:ODB], Yres[SDB:ODB]\n",
    "\n",
    "Xtrain5, Xtest5, Ytrain5, Ytest5 = train_test_split(Xres, Yres, test_size = 0.20, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YX-06H7i5F2"
   },
   "source": [
    "Entrenamos con KNN cada uno de los 5 grupos de datos\n",
    "Nota: Es posible elegir qué métrica ('MSE', 'TdC', 'Exactitud', 'Precision', 'Recall' o 'F1') tomar como referencia, en este caso se elige 'Precision'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6Nud9b0jIMp",
    "outputId": "155b87ef-fad1-4758-e0a6-a00811123b1d"
   },
   "outputs": [],
   "source": [
    "model1 = KNN()\n",
    "model1.fit(Xtrain1, Ytrain1, Xtest1, Ytest1, fEpocasP = 5, fpriorityP = 'Precision')\n",
    "print('')\n",
    "model2 = KNN()\n",
    "model2.fit(Xtrain2, Ytrain2, Xtest2, Ytest2, fEpocasP = 5, fpriorityP = 'Precision')\n",
    "print('')\n",
    "model3 = KNN()\n",
    "model3.fit(Xtrain3, Ytrain3, Xtest3, Ytest3, fEpocasP = 5, fpriorityP = 'Precision')\n",
    "print('')\n",
    "model4 = KNN()\n",
    "model4.fit(Xtrain4, Ytrain4, Xtest4, Ytest4, fEpocasP = 5, fpriorityP = 'Precision')\n",
    "print('')\n",
    "model5 = KNN()\n",
    "model5.fit(Xtrain5, Ytrain5, Xtest5, Ytest5, fEpocasP = 5, fpriorityP = 'Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNm15ibjn5GX"
   },
   "source": [
    "Determinamos la precisión individual de cada modelo y la precisión final del análisis K-Fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UoydmrbyroLh"
   },
   "outputs": [],
   "source": [
    "Stadistic1 = model1.get_stadistict('Precision')\n",
    "Stadistic2 = model2.get_stadistict('Precision')\n",
    "Stadistic3 = model3.get_stadistict('Precision')\n",
    "Stadistic4 = model4.get_stadistict('Precision')\n",
    "Stadistic5 = model5.get_stadistict('Precision')\n",
    "\n",
    "StadisticFin = (Stadistic1 + Stadistic2 + Stadistic3 + Stadistic4 + Stadistic5) / 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkVI4Kk8sjhX"
   },
   "source": [
    "Desplegamos las precisiones determinadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SASXaFofsi5f",
    "outputId": "b5688238-bab4-4d89-dd4f-987bd9f7f249"
   },
   "outputs": [],
   "source": [
    "print('Precisión 1 =', str(Stadistic1) + '.')\n",
    "print('Precisión 2 =', str(Stadistic2) + '.')\n",
    "print('Precisión 3 =', str(Stadistic3) + '.')\n",
    "print('Precisión 4 =', str(Stadistic4) + '.')\n",
    "print('Precisión 5 =', str(Stadistic5) + '.')\n",
    "print('Precisión final =', str(StadisticFin) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xd02o0SAALzW"
   },
   "source": [
    "## Evaluamos el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdlAiLLC928_"
   },
   "source": [
    "Se evaluará con los datos de validación anteriormente seleccionados de los datos globales, los cuales no se utilizaron durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4joYEI7Yjj4u"
   },
   "source": [
    "### Obtenemos el vector de predicciones de cada modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5S__mcCsCxu"
   },
   "source": [
    "Nota: Se elige el modelo con la mayor presición, de acuerdo a las obtenidas en el paso anterior, en este caso del modelo 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "enhzT8i7nEfa"
   },
   "outputs": [],
   "source": [
    "YvalPred = []\n",
    "for element in Xval:\n",
    "  YvalPred.append(model1.PrednewPoint(element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MezwzihAcLL"
   },
   "source": [
    "### Analizamos métricas de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "009H9RJn6mLD",
    "outputId": "048b30fb-aa18-431b-e69d-6582ba104d4d"
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "ModelStatistics = Estadisticas(YvalPred, Yval)\n",
    "\n",
    "STable = [ ['MSE', str(ModelStatistics[0])],\n",
    "     ['Tasa de clasificación', str(ModelStatistics[1])],\n",
    "     ['Exactitud', str(ModelStatistics[2])],\n",
    "     ['Precisión', str(ModelStatistics[3])],\n",
    "     ['Recall', str(ModelStatistics[4])],\n",
    "     ['F1', str(ModelStatistics[5])] ]\n",
    "\n",
    "print(tabulate(STable, headers = ['Métrica', 'Valor'], tablefmt=\"presto\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwE70cUS6IER"
   },
   "source": [
    "Obtenemos la matriz de confusión de los datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "JuLTOdVl14Id",
    "outputId": "1f657afb-4da7-4505-c250-a3eb3d58b5b5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(Yval, YvalPred, labels = np.unique(Yval))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = np.unique(Yval))\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ZgKjhfatOHNy",
    "lTpPPDKh791N",
    "ipND8eHZ-VnE",
    "b10zOnwH_en0",
    "SlfcnVhf-Z6g",
    "jiRC_o30AA-h",
    "xd02o0SAALzW",
    "5EsWrpu3ASJL"
   ],
   "name": "KNN_JIOG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
